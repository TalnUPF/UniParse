2019-05-30 13:15:34,502:INFO:	
2019-05-30 13:15:34,502:INFO:	
2019-05-30 13:15:34,502:INFO:	
2019-05-30 13:15:34,502:INFO:	===================================================================================================
2019-05-30 13:15:34,502:INFO:	kiperwasser_main
2019-05-30 13:15:34,502:INFO:	===================================================================================================
2019-05-30 13:15:34,502:INFO:	
2019-05-30 13:15:34,502:INFO:	
2019-05-30 13:15:34,502:INFO:	Arguments:
2019-05-30 13:15:34,502:INFO:	Namespace(batch_size=32, big_dataset=True, dev='/home/lpmayos/code/datasets/1-billion-word-language-modeling-benchmark-r13output/conll_bpe_mini/1b_dev.bpe.conllu', dev_mode=False, do_training=True, embs=None, epochs=30, logging_file='logging.log', model_file='model_1B_mini_bpe.model', no_update_pretrained_emb=False, output_file='output_1B_mini_bpe.output', patience=-1, results_folder='/home/lpmayos/code/UniParse/saved_models/kiperwasser_en_1B_mini', tb_dest=None, test='/home/lpmayos/code/datasets/1-billion-word-language-modeling-benchmark-r13output/conll_bpe_mini/1b_test.bpe.conllu', train='/home/lpmayos/code/datasets/1-billion-word-language-modeling-benchmark-r13output/conll_bpe_mini/1b_train.bpe.conllu', vocab_file='vocab_1B_mini_bpe.pkl')
2019-05-30 13:15:34,502:INFO:	
2019-05-30 13:15:34,512:INFO:	Training with big dataset; subset_size = 10000
2019-05-30 13:15:34,513:DEBUG:	Init training with big dataset (there is no dev mode)
2019-05-30 13:15:34,513:INFO:	tokenizing dev data ...
2019-05-30 13:15:35,874:INFO:	... tokenized dev data
2019-05-30 13:15:35,874:INFO:	creating model ...
2019-05-30 13:15:35,898:INFO:	... model created
2019-05-30 13:15:35,898:INFO:	creating ModelSaveCallback ...
2019-05-30 13:15:35,898:INFO:	saving model to /home/lpmayos/code/UniParse/saved_models/kiperwasser_en_1B_mini/model_1B_mini_bpe.model  (after step 0)
2019-05-30 13:15:35,898:INFO:	... ModelSaveCallback created
2019-05-30 13:15:35,898:INFO:	creating Model ...
2019-05-30 13:15:35,899:INFO:	... Model created
2019-05-30 13:15:35,899:INFO:	training Model ...
2019-05-30 13:15:35,899:DEBUG:	...Training without patience for exactly 30 epochs
2019-05-30 13:15:35,899:INFO:	Epoch 1
2019-05-30 13:15:35,899:INFO:	=====================
