#!/bin/bash
#SBATCH --job-name="intel_uniparse"
#SBATCH -n 1
#SBATCH -N 1
#SBATCH --mem=128000
#SBATCH -p high
#SBATCH --gres=gpu:2                      # ask for a gpu resource

module load Tensorflow-gpu/1.12.0-foss-2017a-Python-3.6.4
module load scikit-learn/0.19.1-foss-2017a-Python-3.6.4
module load dynet/2.1-foss-2017a-Python-3.6.4-GPU-CUDA-9.0.176
# compiling decoders

python setup.py build_ext --inplace


# training and running model 

# python kiperwasser_main.py --results_folder /homedtic/lperez/UniParse/saved_models/kiperwasser_en_ud_test_hpc --logging_file logging.log --do_training True --train_file /homedtic/lperez/UniParse/datasets/ud2.1/en-ud-train.conllu --dev_file /homedtic/lperez/UniParse/datasets/ud2.1/en-ud-dev.conllu --test_file /homedtic/lperez/UniParse/datasets/ud2.1/en-ud-test.conllu --output_file prova.output --model_file model.model --vocab_file vocab.pkl --dev_mode True --epochs 2 --dynet-devices GPU:0

python kiperwasser_main.py --results_folder /homedtic/lperez/UniParse/saved_models/kiperwasser_en_1b_2gpu --logging_file logging_1b3.log --do_training True --train_file /homedtic/lperez/UniParse/datasets/1-billion-benchmark/1B_train.conllu --dev_file /homedtic/lperez/UniParse/datasets/1-billion-benchmark/1B_dev.conllu --test_file /homedtic/lperez/UniParse/datasets/1-billion-benchmark/1B_test.conllu --output_file output_1b3.output --model_file model_1b3.model --vocab_file vocab3.pkl --dynet-devices GPU:0,GPU:1
